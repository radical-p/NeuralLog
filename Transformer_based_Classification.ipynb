{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radical-p/NeuralLog/blob/main/Transformer_based_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwFyen9PamnP",
        "outputId": "c8cfcc9b-580f-47ee-dbff-dbe3a5bb3154",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug  1 07:51:20 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLFhbl0yi63A",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c90a173c-627a-4ed1-8e26-c3c1b10abf65"
      },
      "source": [
        "pip install -q tf-models-official"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.7.0 requires PyYAML>=5.4.1, but you have pyyaml 5.3.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx3lltd58zkg",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYQGTcl_86xy",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from official.nlp import optimization"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95b_uEPLgSIq",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "sMt-bF2esd5w",
        "outputId": "84a2e9b9-1032-4a28-877e-1169e0d56429"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.24.3)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.3\n",
            "    Uninstalling numpy-1.24.3:\n",
            "      Successfully uninstalled numpy-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.7.0 requires PyYAML>=5.4.1, but you have pyyaml 5.3.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.25.2 which is incompatible.\n",
            "tensorflow 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.25.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqf3h3Sh88xN",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "#from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1kFJDLP8bwe",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Liu0qGrAVNxp",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# II. Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PUKB02N_QTF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7taKfNmh8e5B",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM6iBfZP6U6C",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "class PositionEmbedding(layers.Layer):\n",
        "    def __init__(self, max_len, vocab_size, embed_dim):\n",
        "        super(PositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_encoding = positional_encoding(max_len,\n",
        "                                                embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mziDCzBZ8g2q",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "embed_dim = 768  # Embedding size for each token\n",
        "num_heads = 12  # Number of attention heads\n",
        "ff_dim = 2048  # Hidden layer size in feed forward network inside transformer\n",
        "max_len = 75\n",
        "num_layers = 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC3Duqe08qkZ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "def transformer_classifer(input_size, loss_object, optimizer, dropout=0.1):\n",
        "    inputs = layers.Input(shape=(max_len, embed_dim))\n",
        "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "    embedding_layer = PositionEmbedding(100, 2000, embed_dim)\n",
        "    x = embedding_layer(inputs)\n",
        "    x = transformer_block(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(loss=loss_object, metrics=['accuracy'],\n",
        "                  optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abg-kaEbXYKM",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Training/Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3y6Us-99Jyk",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "class BatchGenerator(Sequence):\n",
        "\n",
        "    def __init__(self, X, Y, batch_size):\n",
        "        self.X, self.Y = X, Y\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.X) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # print(self.batch_size)\n",
        "        dummy = np.zeros(shape=(embed_dim,))\n",
        "        x = self.X[idx * self.batch_size:min((idx + 1) * self.batch_size, len(self.X))]\n",
        "        X = np.zeros((len(x), max_len, embed_dim))\n",
        "        Y = np.zeros((len(x), 2))\n",
        "        item_count = 0\n",
        "        for i in range(idx * self.batch_size, min((idx + 1) * self.batch_size, len(self.X))):\n",
        "            x = self.X[i]\n",
        "            if len(x) > max_len:\n",
        "                x = x[-max_len:]\n",
        "            x = np.pad(np.array(x), pad_width=((max_len - len(x), 0), (0, 0)), mode='constant',\n",
        "                       constant_values=0)\n",
        "            X[item_count] = np.reshape(x, [max_len, embed_dim])\n",
        "            Y[item_count] = self.Y[i]\n",
        "            item_count += 1\n",
        "        return X[:], Y[:, 0]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hry6lv0psLS",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XZXMT8-9TtR",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "def train_generator(training_generator, validate_generator, num_train_samples, num_val_samples, batch_size,\n",
        "                      epoch_num, model_name=None):\n",
        "\n",
        "    optim = Adam()\n",
        "    epochs = epoch_num\n",
        "    steps_per_epoch = num_train_samples\n",
        "    num_train_steps = steps_per_epoch * epochs\n",
        "    num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "    init_lr = 3e-4\n",
        "    optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                              num_train_steps=num_train_steps,\n",
        "                                              num_warmup_steps=num_warmup_steps,\n",
        "                                              optimizer_type='adamw')\n",
        "\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "    model = transformer_classifer(768, loss_object, optimizer)\n",
        "\n",
        "    # model.load_weights(\"hdfs_transformer.hdf5\")\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    # checkpoint\n",
        "    filepath = model_name\n",
        "    checkpoint = ModelCheckpoint(filepath,\n",
        "                                 monitor='val_accuracy',\n",
        "                                 verbose=1,\n",
        "                                 save_best_only=True,\n",
        "                                 mode='max',\n",
        "                                 save_weights_only=True)\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto',\n",
        "        baseline=None, restore_best_weights=True\n",
        "    )\n",
        "    callbacks_list = [checkpoint, early_stop]\n",
        "\n",
        "    # class_weight = {0: 245., 1: 1.}\n",
        "\n",
        "    model.fit_generator(generator=training_generator,\n",
        "                        steps_per_epoch=int(num_train_samples / batch_size),\n",
        "                        epochs=epoch_num,\n",
        "                        verbose=1,\n",
        "                        validation_data=validate_generator,\n",
        "                        validation_steps=int(num_val_samples / batch_size),\n",
        "                        workers=16,\n",
        "                        max_queue_size=32,\n",
        "                        callbacks=callbacks_list,\n",
        "                        shuffle=True\n",
        "                        # class_weight=class_weight\n",
        "                        )\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRNVSLuwVHm2",
        "outputId": "70b2c627-f871-424c-9c2f-0687e26cde51"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_7UPOMJ9HBQ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "\n",
        "def plot_confusion_matrix(actual, predicted):\n",
        "  confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
        "\n",
        "  cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
        "\n",
        "  cm_display.plot()\n",
        "  plt.show()\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "def train(X, Y, epoch_num, batch_size, tx, ty, model_file=None):\n",
        "    X, Y = shuffle(X, Y)\n",
        "    n_samples = len(X)\n",
        "    train_x, train_y = X[:int(n_samples * 90 / 100)], Y[:int(n_samples * 90 / 100)]\n",
        "    val_x, val_y = X[int(n_samples * 90 / 100):], Y[int(n_samples * 90 / 100):]\n",
        "\n",
        "    training_generator, num_train_samples = BatchGenerator(train_x, train_y, batch_size), len(train_x)\n",
        "    validate_generator, num_val_samples = BatchGenerator(val_x, val_y, batch_size), len(val_x)\n",
        "\n",
        "    print(\"Number of training samples: {0} - Number of validating samples: {1}\".format(num_train_samples,\n",
        "                                                                                       num_val_samples))\n",
        "\n",
        "    model = train_generator(training_generator, validate_generator, num_train_samples, num_val_samples, batch_size,\n",
        "                              epoch_num, model_name=model_file)\n",
        "    test_model(model, tx, ty, batch_size)\n",
        "    return model\n",
        "\n",
        "\n",
        "def test_model(model, x, y, batch_size):\n",
        "    #x, y = shuffle(x, y)\n",
        "    x, y = x[: len(x) // batch_size * batch_size], y[: len(y) // batch_size * batch_size]\n",
        "    test_loader = BatchGenerator(x, y, batch_size)\n",
        "    prediction = model.predict_generator(test_loader, steps=(len(x) // batch_size), workers=16, max_queue_size=32,\n",
        "                                         verbose=1)\n",
        "    prediction = np.argmax(prediction, axis=1)\n",
        "    y = y[:len(prediction)]\n",
        "\n",
        "    report = classification_report(np.array(y), prediction)\n",
        "    print(report)\n",
        "\n",
        "    plot_confusion_matrix(np.array(y), prediction)\n",
        "    return prediction"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BKGP36V9A1i",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFM5sqXJ8tHg",
        "outputId": "e97c044d-f0d1-491d-9789-2a255e0497d0",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "with open(\"/content/drive/MyDrive/neural-train.pkl\", mode=\"rb\") as f:\n",
        "    (x_tr, y_tr) = pickle.load(f)\n",
        "#x_tr, y_tr = shuffle(x_tr, y_tr)\n",
        "print(Counter(y_tr))\n",
        "with open(\"/content/drive/MyDrive/neural-test.pkl\", mode=\"rb\") as f:\n",
        "    (x_te, y_te) = pickle.load(f)\n",
        "print(Counter(y_te))\n",
        "print(\"Data loaded\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 446559, 1: 13489})\n",
            "Counter({0: 111664, 1: 3349})\n",
            "Data loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qC3cZmR9F26",
        "outputId": "267ac46c-6ef0-4a30-c7f5-1c68a9e79459",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "model = train(x_tr, y_tr, 1, 32, x_te, y_te, \"hdfs_transformer.hdf5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 414043 - Number of validating samples: 46005\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 75, 768)]         0         \n",
            "                                                                 \n",
            " position_embedding (Positi  (None, 75, 768)           0         \n",
            " onEmbedding)                                                    \n",
            "                                                                 \n",
            " transformer_block (Transfo  (None, 75, 768)           31491584  \n",
            " rmerBlock)                                                      \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 768)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                24608     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31516258 (120.22 MB)\n",
            "Trainable params: 31516258 (120.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-16-e829109666c2>:44: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator=training_generator,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12938/12938 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9909\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99893, saving model to hdfs_transformer.hdf5\n",
            "12938/12938 [==============================] - 1951s 150ms/step - loss: 0.0343 - accuracy: 0.9909 - val_loss: 0.0058 - val_accuracy: 0.9989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ed8011676196>:23: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  prediction = model.predict_generator(test_loader, steps=(len(x) // batch_size), workers=16, max_queue_size=32,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3594/3594 [==============================] - 213s 59ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    111659\n",
            "           1       0.97      0.99      0.98      3349\n",
            "\n",
            "    accuracy                           1.00    115008\n",
            "   macro avg       0.99      0.99      0.99    115008\n",
            "weighted avg       1.00      1.00      1.00    115008\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(x_tr[0]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W5APQ9Av-M1",
        "outputId": "e29eef1f-c858-4b3f-b95e-f16473a7097a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = test_model(model, x_te[0:1], y_te[0:1], 1)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "D0HoEvIvw3vP",
        "outputId": "d6cb04bd-ac44-4793-95a2-eeec89aa2036"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-5e3c909fb5f6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_te\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_te\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = Adam()\n",
        "pre_model = transformer_classifer(768, loss_object, optimizer)\n",
        "pre_model.load_weights(\"/content/drive/MyDrive/hdfs_transformer.hdf5\")"
      ],
      "metadata": {
        "id": "eKdOCmiAxCdr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = test_model(pre_model, x_te[0:4000], y_te[0:4000], 1)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "ygsZCucMZann",
        "outputId": "4186b4d5-e42b-4c0a-90a3-b81a43c066e7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-7724b0106675>:37: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  prediction = model.predict_generator(test_loader, steps=(len(x) // batch_size), workers=16, max_queue_size=32,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000/4000 [==============================] - 25s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3885\n",
            "           1       1.00      0.99      1.00       115\n",
            "\n",
            "    accuracy                           1.00      4000\n",
            "   macro avg       1.00      1.00      1.00      4000\n",
            "weighted avg       1.00      1.00      1.00      4000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY_7RTT5Zlry",
        "outputId": "4cba4e66-98c2-4fc8-f57e-3121259ae4e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.42.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.65.0)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.1)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.7)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.56.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->shap) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "# explain the model's predictions using SHAP\n",
        "# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
        "explainer = shap.Explainer(pre_model)\n",
        "shap_values = explainer(np.array(x_tr[0:400]))\n",
        "\n",
        "# visualize the first prediction's explanation\n",
        "shap.plots.waterfall(shap_values[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "1IsKEHyUfMc6",
        "outputId": "8a1bd23e-9009-4616-bd54-e5557fa69e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-961badd44eff>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# visualize the first prediction's explanation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_permutation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\" Explain the output of the model on the given arguments.\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         return super().__call__(\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_bounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_explainer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" explainer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             row_result = self.explain_row(\n\u001b[0m\u001b[1;32m    265\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mrow_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_permutation.py\u001b[0m in \u001b[0;36mexplain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *row_args)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# build a masked version of the model for the current input sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinearize_link\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrow_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# by default we run 10 permutations forward and backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, masker, link, linearize_link, *args)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_masker_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;31m# # just assuming...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_masker_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linearizing_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_masker_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;31m# # just assuming...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_masker_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linearizing_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W-JYa7JFf3Fr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}