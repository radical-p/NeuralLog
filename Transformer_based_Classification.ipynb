{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radical-p/NeuralLog/blob/main/Transformer_based_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwFyen9PamnP",
        "outputId": "98a63ace-01cc-4436-f9ed-f7b38c483f65",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug  1 09:17:41 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLFhbl0yi63A",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c8ea3a-f0dd-42fa-dd47-24bd874a2230"
      },
      "source": [
        "pip install -q tf-models-official"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.7.0 requires PyYAML>=5.4.1, but you have pyyaml 5.3.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx3lltd58zkg",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYQGTcl_86xy",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from official.nlp import optimization"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95b_uEPLgSIq",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "sMt-bF2esd5w",
        "outputId": "055686be-b2d1-4308-e682-5c043ef964fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.7.0 requires PyYAML>=5.4.1, but you have pyyaml 5.3.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.25.2 which is incompatible.\n",
            "tensorflow 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.25.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqf3h3Sh88xN",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "#from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1kFJDLP8bwe",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Liu0qGrAVNxp",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# II. Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PUKB02N_QTF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7taKfNmh8e5B",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM6iBfZP6U6C",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "class PositionEmbedding(layers.Layer):\n",
        "    def __init__(self, max_len, vocab_size, embed_dim):\n",
        "        super(PositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_encoding = positional_encoding(max_len,\n",
        "                                                embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mziDCzBZ8g2q",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "embed_dim = 768  # Embedding size for each token\n",
        "num_heads = 12  # Number of attention heads\n",
        "ff_dim = 2048  # Hidden layer size in feed forward network inside transformer\n",
        "max_len = 75\n",
        "num_layers = 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC3Duqe08qkZ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "def transformer_classifer(input_size, loss_object, optimizer, dropout=0.1):\n",
        "    inputs = layers.Input(shape=(max_len, embed_dim))\n",
        "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "    embedding_layer = PositionEmbedding(100, 2000, embed_dim)\n",
        "    x = embedding_layer(inputs)\n",
        "    x = transformer_block(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(loss=loss_object, metrics=['accuracy'],\n",
        "                  optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abg-kaEbXYKM",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Training/Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3y6Us-99Jyk",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "class BatchGenerator(Sequence):\n",
        "\n",
        "    def __init__(self, X, Y, batch_size):\n",
        "        self.X, self.Y = X, Y\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.X) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # print(self.batch_size)\n",
        "        dummy = np.zeros(shape=(embed_dim,))\n",
        "        x = self.X[idx * self.batch_size:min((idx + 1) * self.batch_size, len(self.X))]\n",
        "        X = np.zeros((len(x), max_len, embed_dim))\n",
        "        Y = np.zeros((len(x), 2))\n",
        "        item_count = 0\n",
        "        for i in range(idx * self.batch_size, min((idx + 1) * self.batch_size, len(self.X))):\n",
        "            x = self.X[i]\n",
        "            if len(x) > max_len:\n",
        "                x = x[-max_len:]\n",
        "            x = np.pad(np.array(x), pad_width=((max_len - len(x), 0), (0, 0)), mode='constant',\n",
        "                       constant_values=0)\n",
        "            X[item_count] = np.reshape(x, [max_len, embed_dim])\n",
        "            Y[item_count] = self.Y[i]\n",
        "            item_count += 1\n",
        "        return X[:], Y[:, 0]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hry6lv0psLS",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XZXMT8-9TtR",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "def train_generator(training_generator, validate_generator, num_train_samples, num_val_samples, batch_size,\n",
        "                      epoch_num, model_name=None):\n",
        "\n",
        "    optim = Adam()\n",
        "    epochs = epoch_num\n",
        "    steps_per_epoch = num_train_samples\n",
        "    num_train_steps = steps_per_epoch * epochs\n",
        "    num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "    init_lr = 3e-4\n",
        "    optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                              num_train_steps=num_train_steps,\n",
        "                                              num_warmup_steps=num_warmup_steps,\n",
        "                                              optimizer_type='adamw')\n",
        "\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "    model = transformer_classifer(768, loss_object, optimizer)\n",
        "\n",
        "    # model.load_weights(\"hdfs_transformer.hdf5\")\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    # checkpoint\n",
        "    filepath = model_name\n",
        "    checkpoint = ModelCheckpoint(filepath,\n",
        "                                 monitor='val_accuracy',\n",
        "                                 verbose=1,\n",
        "                                 save_best_only=True,\n",
        "                                 mode='max',\n",
        "                                 save_weights_only=True)\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto',\n",
        "        baseline=None, restore_best_weights=True\n",
        "    )\n",
        "    callbacks_list = [checkpoint, early_stop]\n",
        "\n",
        "    # class_weight = {0: 245., 1: 1.}\n",
        "\n",
        "    model.fit_generator(generator=training_generator,\n",
        "                        steps_per_epoch=int(num_train_samples / batch_size),\n",
        "                        epochs=epoch_num,\n",
        "                        verbose=1,\n",
        "                        validation_data=validate_generator,\n",
        "                        validation_steps=int(num_val_samples / batch_size),\n",
        "                        workers=16,\n",
        "                        max_queue_size=32,\n",
        "                        callbacks=callbacks_list,\n",
        "                        shuffle=True\n",
        "                        # class_weight=class_weight\n",
        "                        )\n",
        "    return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lRNVSLuwVHm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_7UPOMJ9HBQ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "\n",
        "def plot_confusion_matrix(actual, predicted):\n",
        "  confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
        "\n",
        "  cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['Negative', 'Positive'])\n",
        "\n",
        "  cm_display.plot()\n",
        "  plt.show()\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "def train(X, Y, epoch_num, batch_size, tx, ty, model_file=None):\n",
        "    X, Y = shuffle(X, Y)\n",
        "    n_samples = len(X)\n",
        "    train_x, train_y = X[:int(n_samples * 90 / 100)], Y[:int(n_samples * 90 / 100)]\n",
        "    val_x, val_y = X[int(n_samples * 90 / 100):], Y[int(n_samples * 90 / 100):]\n",
        "\n",
        "    training_generator, num_train_samples = BatchGenerator(train_x, train_y, batch_size), len(train_x)\n",
        "    validate_generator, num_val_samples = BatchGenerator(val_x, val_y, batch_size), len(val_x)\n",
        "\n",
        "    print(\"Number of training samples: {0} - Number of validating samples: {1}\".format(num_train_samples,\n",
        "                                                                                       num_val_samples))\n",
        "\n",
        "    model = train_generator(training_generator, validate_generator, num_train_samples, num_val_samples, batch_size,\n",
        "                              epoch_num, model_name=model_file)\n",
        "    test_model(model, tx, ty, batch_size)\n",
        "    return model\n",
        "\n",
        "\n",
        "def test_model(model, x, y, batch_size):\n",
        "    #x, y = shuffle(x, y)\n",
        "    x, y = x[: len(x) // batch_size * batch_size], y[: len(y) // batch_size * batch_size]\n",
        "    test_loader = BatchGenerator(x, y, batch_size)\n",
        "    prediction = model.predict_generator(test_loader, steps=(len(x) // batch_size), workers=16, max_queue_size=32,\n",
        "                                         verbose=1)\n",
        "    prediction = np.argmax(prediction, axis=1)\n",
        "    y = y[:len(prediction)]\n",
        "\n",
        "    report = classification_report(np.array(y), prediction)\n",
        "    print(report)\n",
        "\n",
        "    plot_confusion_matrix(np.array(y), prediction)\n",
        "    return prediction"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BKGP36V9A1i",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFM5sqXJ8tHg",
        "outputId": "82ba3ea1-021c-490c-a5fb-893c3ebd31e4",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "with open(\"/content/drive/MyDrive/neural-train.pkl\", mode=\"rb\") as f:\n",
        "    (x_tr, y_tr) = pickle.load(f)\n",
        "#x_tr, y_tr = shuffle(x_tr, y_tr)\n",
        "print(Counter(y_tr))\n",
        "with open(\"/content/drive/MyDrive/neural-test.pkl\", mode=\"rb\") as f:\n",
        "    (x_te, y_te) = pickle.load(f)\n",
        "print(Counter(y_te))\n",
        "print(\"Data loaded\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 446559, 1: 13489})\n",
            "Counter({0: 111664, 1: 3349})\n",
            "Data loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qC3cZmR9F26",
        "outputId": "267ac46c-6ef0-4a30-c7f5-1c68a9e79459",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "model = train(x_tr, y_tr, 1, 32, x_te, y_te, \"hdfs_transformer.hdf5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 414043 - Number of validating samples: 46005\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 75, 768)]         0         \n",
            "                                                                 \n",
            " position_embedding (Positi  (None, 75, 768)           0         \n",
            " onEmbedding)                                                    \n",
            "                                                                 \n",
            " transformer_block (Transfo  (None, 75, 768)           31491584  \n",
            " rmerBlock)                                                      \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 768)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                24608     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31516258 (120.22 MB)\n",
            "Trainable params: 31516258 (120.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-16-e829109666c2>:44: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator=training_generator,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12938/12938 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9909\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99893, saving model to hdfs_transformer.hdf5\n",
            "12938/12938 [==============================] - 1951s 150ms/step - loss: 0.0343 - accuracy: 0.9909 - val_loss: 0.0058 - val_accuracy: 0.9989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ed8011676196>:23: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  prediction = model.predict_generator(test_loader, steps=(len(x) // batch_size), workers=16, max_queue_size=32,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3594/3594 [==============================] - 213s 59ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    111659\n",
            "           1       0.97      0.99      0.98      3349\n",
            "\n",
            "    accuracy                           1.00    115008\n",
            "   macro avg       0.99      0.99      0.99    115008\n",
            "weighted avg       1.00      1.00      1.00    115008\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(x_tr[0]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W5APQ9Av-M1",
        "outputId": "e29eef1f-c858-4b3f-b95e-f16473a7097a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = Adam()\n",
        "pre_model = transformer_classifer(768, loss_object, optimizer)\n",
        "pre_model.load_weights(\"/content/drive/MyDrive/hdfs_transformer.hdf5\")"
      ],
      "metadata": {
        "id": "eKdOCmiAxCdr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = test_model(pre_model, x_te[0:8000], y_te[0:8000], 1)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "ygsZCucMZann",
        "outputId": "2e795907-6751-4cfa-c051-178de5a32540"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-f706a94a752a>:37: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  prediction = model.predict_generator(test_loader, steps=(len(x) // batch_size), workers=16, max_queue_size=32,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8000/8000 [==============================] - 53s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      7780\n",
            "           1       1.00      1.00      1.00       220\n",
            "\n",
            "    accuracy                           1.00      8000\n",
            "   macro avg       1.00      1.00      1.00      8000\n",
            "weighted avg       1.00      1.00      1.00      8000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "pY_7RTT5Zlry",
        "outputId": "4e51b07a-0209-415a-a33b-a548a0364244"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.42.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (547 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/547.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m30.7/547.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m122.9/547.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m547.9/547.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.24.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.65.0)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.1)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.56.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.39.1)\n",
            "Collecting numpy (from shap)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->shap) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, numpy, shap\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.3\n",
            "    Uninstalling numpy-1.24.3:\n",
            "      Successfully uninstalled numpy-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.7.0 requires PyYAML>=5.4.1, but you have pyyaml 5.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5 shap-0.42.1 slicer-0.0.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "# explain the model's predictions using SHAP\n",
        "# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
        "explainer = shap.Explainer(pre_model)\n",
        "shap_values = explainer(np.array(x_tr[0:400]))\n",
        "\n",
        "# visualize the first prediction's explanation\n",
        "shap.plots.waterfall(shap_values[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "1IsKEHyUfMc6",
        "outputId": "972d104c-cd31-4388-eaa4-068084314850"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-961badd44eff>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# explain the model's predictions using SHAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.42.1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_explanation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExplanation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCohorts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# explainers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/_explanation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mslicer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mObj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSlicer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDimensionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_general\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpChain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from ._clustering import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdelta_minimization_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mhclust\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mhclust_ordering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpartition_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/utils/_clustering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_general\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msafe_isinstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Re-export vectorize decorators and the thread layer querying function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m from numba.np.ufunc import (vectorize, guvectorize, threading_layer,\n\u001b[0m\u001b[1;32m     43\u001b[0m                             \u001b[0mget_num_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_num_threads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                             \u001b[0mset_parallel_chunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_parallel_chunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVectorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGUVectorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguvectorize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyUFunc_None\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyUFunc_Zero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyUFunc_One\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_internal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_exprs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_internal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelUFuncBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParallelGUFuncBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: initialization of _internal failed without raising an exception"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W-JYa7JFf3Fr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}